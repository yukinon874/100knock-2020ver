{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 80. ID番号への変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from functools import reduce\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dir_name, file_name):\n",
    "    with open(f'{dir_name}{file_name}') as f:\n",
    "        X = list()\n",
    "        Y = list()\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            splited_line = line.split('\\t')\n",
    "            X.append(splited_line[0])\n",
    "            Y.append(splited_line[1])\n",
    "        return np.asarray(X), np.asarray(Y)\n",
    "\n",
    "def save_file_npy(dir_name, file_name, x):\n",
    "    np.save(f'{dir_name}{file_name}', x)\n",
    "        \n",
    "def load_file_npy(dir_name, file_name):\n",
    "    return np.load(f'{dir_name}{file_name}').astype(np.float32)\n",
    "\n",
    "def chr2num(y):\n",
    "    converter = dict()\n",
    "    converter['b'] = 0\n",
    "    converter['t'] = 1\n",
    "    converter['e'] = 2\n",
    "    converter['m'] = 3\n",
    "    return np.asarray([converter[article_type] for article_type in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, ytrain = load_data('data/', 'train.txt')\n",
    "xvalid, yvalid = load_data('data/', 'valid.txt')\n",
    "xtest, ytest = load_data('data/', 'test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_word_transformar(train_data:list):\n",
    "    word_count = defaultdict(int)\n",
    "    for data in train_data:\n",
    "        for word in data.split(' '):\n",
    "            if word == '':continue\n",
    "            word_count[word] += 1\n",
    "    sorted_word_count = sorted(word_count.items(), key=lambda x: x[1], reverse=True)\n",
    "    word_transformar = defaultdict(int)\n",
    "    for idx, (word, count) in enumerate(sorted_word_count):\n",
    "        if count < 2:\n",
    "            return word_transformar\n",
    "        else:\n",
    "            word_transformar[word] = idx + 1\n",
    "    return word_transformar\n",
    "    \n",
    "    \n",
    "    \n",
    "def txt2vec(txt_list:list, word_transformar:defaultdict):\n",
    "    txt_vec = list()\n",
    "    wdim = len(word_transformar)\n",
    "    wdim_identity = np.identity(wdim + 1)\n",
    "    for txt in txt_list:\n",
    "        vec = list()\n",
    "        for word in txt.split(' '):\n",
    "            if word == '': continue\n",
    "            vec.append(word_transformar[word])\n",
    "        txt_vec.append(wdim_identity[vec])\n",
    "    return txt_vec\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_transformar = make_word_transformar(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_vec = txt2vec(xtrain, word_transformar)\n",
    "xvalid_vec = txt2vec(xvalid, word_transformar)\n",
    "xtest_vec = txt2vec(xtest, word_transformar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 81. RNNによる予測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 82. 確率的勾配降下法による学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 83. ミニバッチ化・GPU上での学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 84. 単語ベクトルの導入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 85. 双方向RNN・多層化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 86. 畳み込みニューラルネットワーク (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 87. 確率的勾配降下法によるCNNの学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 88. パラメータチューニング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 89. 事前学習済み言語モデルからの転移学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
