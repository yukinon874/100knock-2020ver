{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('./data/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 70. 単語ベクトルの和による特徴量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from functools import reduce\n",
    "from nltk.tokenize import word_tokenize\n",
    "#from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dir_name, file_name):\n",
    "    with open(f'{dir_name}{file_name}') as f:\n",
    "        X = list()\n",
    "        Y = list()\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            splited_line = line.split('\\t')\n",
    "            X.append(splited_line[0])\n",
    "            Y.append(splited_line[1])\n",
    "        return np.asarray(X), np.asarray(Y)\n",
    "\n",
    "def txt2vec(x):\n",
    "    vec_x_list = list()\n",
    "    for text in x:\n",
    "        words = word_tokenize(text)\n",
    "        words_vec = [model[word] for word in words if word in model]\n",
    "        if not words_vec:\n",
    "            print(words)\n",
    "            continue\n",
    "        vec_x_list.append(sum(words_vec) / len(words_vec))\n",
    "    return np.asarray(vec_x_list)\n",
    "\n",
    "def save_file_npy(dir_name, file_name, x):\n",
    "    np.save(f'{dir_name}{file_name}', x)\n",
    "        \n",
    "def load_file_npy(dir_name, file_name):\n",
    "    return np.load(f'{dir_name}{file_name}')\n",
    "\n",
    "def chr2num(y):\n",
    "    converter = {'b':0, 't':1, 'e':2, 'm':3}\n",
    "    return np.asarray([converter[article_type] for article_type in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = load_data('data/', 'train.txt')\n",
    "valid_x, valid_y = load_data('data/', 'valid.txt')\n",
    "test_x, test_y = load_data('data/', 'test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10680,) (10680,)\n",
      "(1335,) (1335,)\n",
      "(1335,) (1335,)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape, train_y.shape)\n",
    "print(valid_x.shape, valid_y.shape)\n",
    "print(test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = txt2vec(train_x)\n",
    "valid_x = txt2vec(valid_x)\n",
    "test_x = txt2vec(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = chr2num(train_y)\n",
    "valid_y = chr2num(valid_y)\n",
    "test_y = chr2num(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file_npy('work/', 'train_x', train_x)\n",
    "save_file_npy('work/', 'train_y', train_y)\n",
    "save_file_npy('work/', 'valid_x', valid_x)\n",
    "save_file_npy('work/', 'valid_y', valid_y)\n",
    "save_file_npy('work/', 'test_x', test_x)\n",
    "save_file_npy('work/', 'test_y', test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 71. 単層ニューラルネットワークによる予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = load_file_npy('work/', 'train_x.npy')\n",
    "train_y = load_file_npy('work/', 'train_y.npy')\n",
    "valid_x = load_file_npy('work/', 'valid_x.npy')\n",
    "valid_y = load_file_npy('work/', 'valid_y.npy')\n",
    "test_x = load_file_npy('work/', 'test_x.npy')\n",
    "test_y = load_file_npy('work/', 'test_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10680, 300) (10680,)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape, train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0766,  0.3599, -0.7820,  0.0715],\n",
      "        [ 0.6648, -0.2868,  1.6206, -1.5967],\n",
      "        [-0.0517, -0.3060,  0.2485, -0.2226],\n",
      "        ...,\n",
      "        [ 0.2647, -0.8119, -0.9138,  0.1027],\n",
      "        [-0.7688, -1.7742, -1.8339,  0.5013],\n",
      "        [ 0.6518, -0.1978,  0.7931, -1.5037]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(3)\n",
    "W = torch.randn(300, 4)\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.from_numpy(train_x)\n",
    "train_y = torch.from_numpy(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2599, 0.1483, 0.5256, 0.0662]])\n"
     ]
    }
   ],
   "source": [
    "print(F.softmax(torch.matmul(train_x[:1], W), dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2599, 0.1483, 0.5256, 0.0662],\n",
      "        [0.0845, 0.0077, 0.8012, 0.1066],\n",
      "        [0.1564, 0.0854, 0.7054, 0.0527],\n",
      "        [0.0561, 0.0441, 0.7722, 0.1276]])\n"
     ]
    }
   ],
   "source": [
    "print(F.softmax(torch.matmul(train_x[:4], W), dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 72. 損失と勾配の計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-1.1258, -1.1524, -0.2506, -0.4339],\n",
      "        [ 0.8487,  0.6920, -0.3160, -2.1152],\n",
      "        [ 0.3223, -1.2633,  0.3500,  0.3081],\n",
      "        ...,\n",
      "        [ 1.1469, -0.1733,  0.0637, -1.2699],\n",
      "        [-0.6212, -0.2381,  0.0892,  1.8008],\n",
      "        [-2.0627,  0.3222, -1.1390,  1.2418]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "W = nn.Parameter(torch.randn(300, 4), requires_grad=True)\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "v_train_x = train_x[:4]\n",
    "v_train_y = train_y[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0170, -0.0622, -0.0194,  ..., -0.0100,  0.1557, -0.0435],\n",
      "        [-0.0488,  0.0571,  0.1176,  ...,  0.0959,  0.1008,  0.0121],\n",
      "        [ 0.0923,  0.0072, -0.2906,  ...,  0.0138,  0.0388, -0.0379],\n",
      "        [ 0.0472, -0.0069, -0.0391,  ..., -0.0337,  0.0504, -0.1157]])\n"
     ]
    }
   ],
   "source": [
    "print(v_train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_train_x = torch.matmul(v_train_x, W)\n",
    "loss = criterion(v_train_x, v_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.4065, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0115,  0.0194, -0.0339,  0.0029],\n",
      "        [-0.0103, -0.0047, -0.0004,  0.0154],\n",
      "        [-0.0262, -0.0441,  0.0811, -0.0108],\n",
      "        ...,\n",
      "        [-0.0178,  0.0115,  0.0053,  0.0010],\n",
      "        [-0.0151,  0.0673, -0.0184, -0.0338],\n",
      "        [-0.0068, -0.0309,  0.0360,  0.0017]])\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "print(W.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-1.1258, -1.1524, -0.2506, -0.4339],\n",
      "        [ 0.8487,  0.6920, -0.3160, -2.1152],\n",
      "        [ 0.3223, -1.2633,  0.3500,  0.3081],\n",
      "        ...,\n",
      "        [ 1.1469, -0.1733,  0.0637, -1.2699],\n",
      "        [-0.6212, -0.2381,  0.0892,  1.8008],\n",
      "        [-2.0627,  0.3222, -1.1390,  1.2418]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "W = nn.Parameter(torch.randn(300, 4), requires_grad=True)\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.matmul(train_x[:1], W)\n",
    "loss = criterion(out, train_y[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.8259, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2397e-04,  1.5989e-02,  8.5838e-04, -1.6971e-02],\n",
      "        [-4.5319e-04, -5.8451e-02, -3.1380e-03,  6.2042e-02],\n",
      "        [-1.4114e-04, -1.8203e-02, -9.7726e-04,  1.9321e-02],\n",
      "        ...,\n",
      "        [-7.3013e-05, -9.4169e-03, -5.0556e-04,  9.9955e-03],\n",
      "        [ 1.1338e-03,  1.4623e-01,  7.8504e-03, -1.5521e-01],\n",
      "        [-3.1683e-04, -4.0864e-02, -2.1938e-03,  4.3374e-02]])\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "print(W.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 73. 確率的勾配降下法による学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = load_file_npy('work/', 'train_x.npy')\n",
    "train_y = load_file_npy('work/', 'train_y.npy')\n",
    "valid_x = load_file_npy('work/', 'valid_x.npy')\n",
    "valid_y = load_file_npy('work/', 'valid_y.npy')\n",
    "test_x = load_file_npy('work/', 'test_x.npy')\n",
    "test_y = load_file_npy('work/', 'test_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-1.1258, -1.1524, -0.2506, -0.4339],\n",
      "        [ 0.8487,  0.6920, -0.3160, -2.1152],\n",
      "        [ 0.3223, -1.2633,  0.3500,  0.3081],\n",
      "        ...,\n",
      "        [ 1.1469, -0.1733,  0.0637, -1.2699],\n",
      "        [-0.6212, -0.2381,  0.0892,  1.8008],\n",
      "        [-2.0627,  0.3222, -1.1390,  1.2418]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "W = nn.Parameter(torch.randn(300, 4), requires_grad=True)\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_x, train_y, op, criterion, W, batch_size=4, nepoch=100):\n",
    "    ntrain = len(train_x)\n",
    "    loss_list = list()\n",
    "    for epoch in tqdm.notebook.tqdm(range(nepoch)):\n",
    "        sum_loss = 0\n",
    "        perm = np.random.permutation(ntrain)\n",
    "        for i in range(0, ntrain, batch_size):\n",
    "            batch_x = torch.from_numpy(train_x[perm[i:i + batch_size]])\n",
    "            batch_y = torch.from_numpy(train_y[perm[i:i + batch_size]])\n",
    "            batch_x = torch.matmul(batch_x, W)\n",
    "            loss = criterion(batch_x, batch_y)\n",
    "            op.zero_grad()\n",
    "            loss.backward()\n",
    "            op.step()\n",
    "            sum_loss += loss.data.item() * len(batch_x)\n",
    "        loss_list.append(sum_loss / ntrain)\n",
    "    return loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6db72630e6ea4a18ad970c2926582fa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ntrain = len(train_x)\n",
    "nepoch = 100\n",
    "op = optim.SGD([W], lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "result = train(train_x, train_y, op, criterion, W, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-2.0084, -0.0870,  0.4193, -1.2856],\n",
      "        [ 0.4284,  0.9958, -0.1726, -2.1407],\n",
      "        [ 0.7639,  0.6409, -2.3561,  0.6676],\n",
      "        ...,\n",
      "        [ 0.4443, -0.0269, -0.8825,  0.2330],\n",
      "        [ 1.7208, -1.4965, -0.3150,  1.1232],\n",
      "        [-2.2433, -1.0501, -0.5166,  2.1715]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9254317359959309, 0.34149034377692755, 0.2993721159433582, 0.27968309584805706, 0.267745152095906, 0.2595121769816251, 0.25359422520635694, 0.2488213407094142, 0.2454812020850184, 0.24248561884453057]\n"
     ]
    }
   ],
   "source": [
    "print(result[::10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0: 0.687041\n",
      "epoch1: 0.476448\n",
      "epoch2: 0.415567\n",
      "epoch3: 0.383298\n",
      "epoch4: 0.362784\n",
      "epoch5: 0.348309\n",
      "epoch6: 0.337385\n",
      "epoch7: 0.328745\n",
      "epoch8: 0.321681\n",
      "epoch9: 0.315753\n",
      "epoch10: 0.310678\n",
      "epoch11: 0.30626\n",
      "epoch12: 0.302367\n",
      "epoch13: 0.298898\n",
      "epoch14: 0.295775\n",
      "epoch15: 0.292946\n",
      "epoch16: 0.290362\n",
      "epoch17: 0.28799\n",
      "epoch18: 0.285801\n",
      "epoch19: 0.28377\n",
      "epoch20: 0.281879\n",
      "epoch21: 0.280112\n",
      "epoch22: 0.278455\n",
      "epoch23: 0.276896\n",
      "epoch24: 0.275428\n",
      "epoch25: 0.27404\n",
      "epoch26: 0.272726\n",
      "epoch27: 0.271478\n",
      "epoch28: 0.270291\n",
      "epoch29: 0.269161\n",
      "epoch30: 0.268083\n",
      "epoch31: 0.267052\n",
      "epoch32: 0.266066\n",
      "epoch33: 0.265122\n",
      "epoch34: 0.264216\n",
      "epoch35: 0.263347\n",
      "epoch36: 0.262511\n",
      "epoch37: 0.261705\n",
      "epoch38: 0.26093\n",
      "epoch39: 0.260184\n",
      "epoch40: 0.259463\n",
      "epoch41: 0.258766\n",
      "epoch42: 0.258094\n",
      "epoch43: 0.257442\n",
      "epoch44: 0.256813\n",
      "epoch45: 0.256203\n",
      "epoch46: 0.255612\n",
      "epoch47: 0.25504\n",
      "epoch48: 0.254484\n",
      "epoch49: 0.253945\n",
      "epoch50: 0.253421\n",
      "epoch51: 0.252912\n",
      "epoch52: 0.252417\n",
      "epoch53: 0.251935\n",
      "epoch54: 0.251465\n",
      "epoch55: 0.251009\n",
      "epoch56: 0.250565\n",
      "epoch57: 0.250132\n",
      "epoch58: 0.249709\n",
      "epoch59: 0.249297\n",
      "epoch60: 0.248896\n",
      "epoch61: 0.248505\n",
      "epoch62: 0.248122\n",
      "epoch63: 0.247748\n",
      "epoch64: 0.247384\n",
      "epoch65: 0.247027\n",
      "epoch66: 0.246678\n",
      "epoch67: 0.246337\n",
      "epoch68: 0.246004\n",
      "epoch69: 0.245678\n",
      "epoch70: 0.245359\n",
      "epoch71: 0.245047\n",
      "epoch72: 0.244741\n",
      "epoch73: 0.244441\n",
      "epoch74: 0.244147\n",
      "epoch75: 0.24386\n",
      "epoch76: 0.243578\n",
      "epoch77: 0.243301\n",
      "epoch78: 0.24303\n",
      "epoch79: 0.242765\n",
      "epoch80: 0.242504\n",
      "epoch81: 0.242248\n",
      "epoch82: 0.241997\n",
      "epoch83: 0.241751\n",
      "epoch84: 0.24151\n",
      "epoch85: 0.241272\n",
      "epoch86: 0.241039\n",
      "epoch87: 0.24081\n",
      "epoch88: 0.240585\n",
      "epoch89: 0.240365\n",
      "epoch90: 0.240147\n",
      "epoch91: 0.239934\n",
      "epoch92: 0.239724\n",
      "epoch93: 0.239518\n",
      "epoch94: 0.239315\n",
      "epoch95: 0.239115\n",
      "epoch96: 0.238918\n",
      "epoch97: 0.238726\n",
      "epoch98: 0.238535\n",
      "epoch99: 0.238348\n",
      "train accuracy: 91.985\n",
      "valid accuracy: 89.9625\n",
      "test accuracy: 90.2622\n"
     ]
    }
   ],
   "source": [
    "! ./src/a.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 74. 正解率の計測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_acc(data_x, data_y, W):\n",
    "    with torch.no_grad():\n",
    "        pred_y = torch.argmax(torch.matmul(torch.from_numpy(data_x), W), dim=1)\n",
    "    return accuracy_score(data_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc=0.9071161048689138\n"
     ]
    }
   ],
   "source": [
    "print(f'test_acc={calc_acc(test_x, test_y, W)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss=0.9185393258426966\n"
     ]
    }
   ],
   "source": [
    "print(f'train_loss={calc_acc(train_x, train_y, W)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 75. 損失と正解率のプロット"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/docs/stable/tensorboard.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execution(data_x, data_y, op, criterion, W, batch_size=4, is_train=True):\n",
    "    ndata = len(data_x)\n",
    "    perm = np.random.permutation(ndata)\n",
    "    sum_loss = 0\n",
    "    for i in range(0, ndata, batch_size):\n",
    "        op.zero_grad()\n",
    "        batch_x = torch.from_numpy(data_x[perm[i:i + batch_size]])\n",
    "        batch_y = torch.from_numpy(data_y[perm[i:i + batch_size]])\n",
    "        if is_train:\n",
    "            out = torch.matmul(batch_x, W)\n",
    "            loss = criterion(out, batch_y)\n",
    "            loss.backward()\n",
    "            op.step()\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                out = torch.matmul(batch_x, W)\n",
    "                loss = criterion(out, batch_y)\n",
    "        sum_loss += loss.data.item() * len(batch_x)\n",
    "    return sum_loss / ndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-1.1258, -1.1524, -0.2506, -0.4339],\n",
      "        [ 0.8487,  0.6920, -0.3160, -2.1152],\n",
      "        [ 0.3223, -1.2633,  0.3500,  0.3081],\n",
      "        ...,\n",
      "        [ 1.1469, -0.1733,  0.0637, -1.2699],\n",
      "        [-0.6212, -0.2381,  0.0892,  1.8008],\n",
      "        [-2.0627,  0.3222, -1.1390,  1.2418]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "W = nn.Parameter(torch.randn(300, 4), requires_grad=True)\n",
    "print(W)\n",
    "ntrain = len(train_x)\n",
    "nepoch = 100\n",
    "op = optim.SGD([W], lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5611e85756b413b882b4432ce9b620c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_writer = SummaryWriter(log_dir='./work/logs/train')\n",
    "valid_writer = SummaryWriter(log_dir='./work/logs/valid')\n",
    "for epoch in tqdm.notebook.tqdm(range(nepoch)):\n",
    "    train_loss = execution(train_x, train_y, op, criterion, W, batch_size=1)\n",
    "    train_writer.add_scalar(\"loss\", train_loss, epoch) \n",
    "    train_writer.add_scalar(\"accuracy\", calc_acc(train_x, train_y, W), epoch)\n",
    "    \n",
    "    valid_loss = execution(valid_x, valid_y, op, criterion, W, batch_size=1, is_train=False)\n",
    "    valid_writer.add_scalar(\"loss\", valid_loss, epoch)\n",
    "    valid_writer.add_scalar(\"accuracy\", calc_acc(valid_x, valid_y, W), epoch)\n",
    "    \n",
    "train_writer.close()\n",
    "valid_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg viewBox=\"0 0 330 200\" xmlns=\"http://www.w3.org/2000/svg\"><g><g><g><g><g><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"48.875\" x2=\"43.875\" y1=\"177\" y2=\"177\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"48.875\" x2=\"43.875\" y1=\"165.20000000000002\" y2=\"165.20000000000002\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"48.875\" x2=\"43.875\" y1=\"153.4\" y2=\"153.4\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"48.875\" x2=\"43.875\" y1=\"141.6\" y2=\"141.6\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"48.875\" x2=\"43.875\" y1=\"129.79999999999998\" y2=\"129.79999999999998\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"48.875\" x2=\"43.875\" y1=\"118.00000000000001\" y2=\"118.00000000000001\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"48.875\" x2=\"43.875\" y1=\"106.2\" y2=\"106.2\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"48.875\" x2=\"43.875\" y1=\"94.39999999999999\" y2=\"94.39999999999999\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"48.875\" x2=\"43.875\" y1=\"82.6\" y2=\"82.6\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"48.875\" x2=\"43.875\" y1=\"70.8\" y2=\"70.8\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"48.875\" x2=\"43.875\" y1=\"58.999999999999986\" y2=\"58.999999999999986\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"48.875\" x2=\"43.875\" y1=\"47.20000000000002\" y2=\"47.20000000000002\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"48.875\" x2=\"43.875\" y1=\"35.400000000000006\" y2=\"35.400000000000006\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"48.875\" x2=\"43.875\" y1=\"23.599999999999994\" y2=\"23.599999999999994\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"48.875\" x2=\"43.875\" y1=\"11.800000000000011\" y2=\"11.800000000000011\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"48.875\" x2=\"43.875\" y1=\"0\" y2=\"0\"/></g><g transform=\"translate(38.875, 0)\"><text dx=\"0em\" dy=\"0.3em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: end; visibility: hidden; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"0\" y=\"177\">0.2</text><text dx=\"0em\" dy=\"0.3em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: end; visibility: inherit; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"0\" y=\"165.20000000000002\">0.22</text><text dx=\"0em\" dy=\"0.3em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: end; visibility: hidden; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"0\" y=\"153.4\">0.24</text><text dx=\"0em\" dy=\"0.3em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: end; visibility: hidden; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"0\" y=\"141.6\">0.26</text><text dx=\"0em\" dy=\"0.3em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: end; visibility: inherit; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"0\" y=\"129.79999999999998\">0.28</text><text dx=\"0em\" dy=\"0.3em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: end; visibility: hidden; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"0\" y=\"118.00000000000001\">0.3</text><text dx=\"0em\" dy=\"0.3em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: end; visibility: hidden; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"0\" y=\"106.2\">0.32</text><text dx=\"0em\" dy=\"0.3em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: end; visibility: inherit; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"0\" y=\"94.39999999999999\">0.34</text><text dx=\"0em\" dy=\"0.3em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: end; visibility: hidden; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"0\" y=\"82.6\">0.36</text><text dx=\"0em\" dy=\"0.3em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: end; visibility: hidden; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"0\" y=\"70.8\">0.38</text><text dx=\"0em\" dy=\"0.3em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: end; visibility: inherit; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"0\" y=\"58.999999999999986\">0.4</text><text dx=\"0em\" dy=\"0.3em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: end; visibility: hidden; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"0\" y=\"47.20000000000002\">0.42</text><text dx=\"0em\" dy=\"0.3em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: end; visibility: hidden; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"0\" y=\"35.400000000000006\">0.44</text><text dx=\"0em\" dy=\"0.3em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: end; visibility: inherit; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"0\" y=\"23.599999999999994\">0.46</text><text dx=\"0em\" dy=\"0.3em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: end; visibility: hidden; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"0\" y=\"11.800000000000011\">0.48</text><text dx=\"0em\" dy=\"0.3em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: end; visibility: hidden; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"0\" y=\"0\">0.5</text></g><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" x1=\"48.875\" x2=\"48.875\" y1=\"0\" y2=\"177\"/></g></g><g clip-path=\"url(#clip_0)\" transform=\"translate(48, 0)\"><clipPath id=\"clip_0\"><rect height=\"177\" width=\"281\"/></clipPath><g><g><g><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"0\" x2=\"0\" y1=\"0\" y2=\"177\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"23.427083333333332\" x2=\"23.427083333333332\" y1=\"0\" y2=\"177\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"46.854166666666664\" x2=\"46.854166666666664\" y1=\"0\" y2=\"177\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"70.28125\" x2=\"70.28125\" y1=\"0\" y2=\"177\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"93.70833333333333\" x2=\"93.70833333333333\" y1=\"0\" y2=\"177\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"117.13541666666667\" x2=\"117.13541666666667\" y1=\"0\" y2=\"177\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"140.5625\" x2=\"140.5625\" y1=\"0\" y2=\"177\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"163.98958333333334\" x2=\"163.98958333333334\" y1=\"0\" y2=\"177\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"187.41666666666666\" x2=\"187.41666666666666\" y1=\"0\" y2=\"177\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"210.84375\" x2=\"210.84375\" y1=\"0\" y2=\"177\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"234.27083333333334\" x2=\"234.27083333333334\" y1=\"0\" y2=\"177\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"257.69791666666663\" x2=\"257.69791666666663\" y1=\"0\" y2=\"177\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"281.125\" x2=\"281.125\" y1=\"0\" y2=\"177\"/></g><g><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"0\" x2=\"281.125\" y1=\"177\" y2=\"177\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"0\" x2=\"281.125\" y1=\"165.20000000000002\" y2=\"165.20000000000002\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"0\" x2=\"281.125\" y1=\"153.4\" y2=\"153.4\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"0\" x2=\"281.125\" y1=\"141.6\" y2=\"141.6\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"0\" x2=\"281.125\" y1=\"129.79999999999998\" y2=\"129.79999999999998\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"0\" x2=\"281.125\" y1=\"118.00000000000001\" y2=\"118.00000000000001\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"0\" x2=\"281.125\" y1=\"106.2\" y2=\"106.2\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"0\" x2=\"281.125\" y1=\"94.39999999999999\" y2=\"94.39999999999999\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"0\" x2=\"281.125\" y1=\"82.6\" y2=\"82.6\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"0\" x2=\"281.125\" y1=\"70.8\" y2=\"70.8\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"0\" x2=\"281.125\" y1=\"58.999999999999986\" y2=\"58.999999999999986\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"0\" x2=\"281.125\" y1=\"47.20000000000002\" y2=\"47.20000000000002\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"0\" x2=\"281.125\" y1=\"35.400000000000006\" y2=\"35.400000000000006\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"0\" x2=\"281.125\" y1=\"23.599999999999994\" y2=\"23.599999999999994\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"0\" x2=\"281.125\" y1=\"11.800000000000011\" y2=\"11.800000000000011\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"0\" x2=\"281.125\" y1=\"0\" y2=\"0\"/></g></g></g><g><g><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(153, 153, 153)\" stroke-width=\"1.5px\" x1=\"0\" x2=\"281.125\" y1=\"295\" y2=\"295\"/></g></g><g><g><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(153, 153, 153)\" stroke-width=\"1.5px\" x1=\"23.427083333333332\" x2=\"23.427083333333332\" y1=\"0\" y2=\"177\"/></g></g><g><g><g><g><g><path d=\"M25.769791666666666,-13.917624354362488L28.1125,23.446527421474457L30.455208333333335,45.38579076528549L32.797916666666666,59.82057720422745L35.140625,69.91227120161057L37.483333333333334,77.48249232769012L39.82604166666667,83.641876578331L42.168749999999996,88.50807428359985L44.51145833333333,92.59258568286896L46.854166666666664,95.60621708631516L49.196875,98.40621054172516L51.53958333333333,101.11758381128311L53.88229166666667,103.1993317604065L56.225,105.03299593925476L58.567708333333336,106.52765274047852L60.91041666666667,107.89577960968018L63.253125000000004,109.51446950435638L65.59583333333333,110.33200830221176L67.93854166666667,111.75496011972427L70.28125,112.56783932447433L72.62395833333333,113.51445764303207L74.96666666666667,114.03640240430832L77.309375,115.22320955991745L79.65208333333334,115.68072885274887L81.99479166666667,116.28278344869614L84.33749999999999,116.69671356678009L86.68020833333334,117.17913091182709L89.02291666666666,117.97825992107391L91.36562500000001,118.45123499631882L93.70833333333333,118.6523887515068L96.05104166666666,119.35203105211258L98.39375,119.5319265127182L100.73645833333333,119.51617181301117L103.07916666666667,120.11692523956299L105.421875,120.41492819786072L107.76458333333333,120.78671097755432L110.10729166666667,120.91853350400925L112.45,121.18363797664642L114.79270833333334,121.31238341331482L117.13541666666667,121.38815015554428L119.47812499999999,121.79993510246277L121.82083333333334,122.05144762992859L124.16354166666666,122.13570713996887L126.50625000000001,122.21129804849625L128.84895833333331,122.4850183725357L131.19166666666666,122.50363916158676L133.53437499999998,122.47065275907516L135.87708333333333,122.51123517751694L138.21979166666665,122.55531668663025L140.5625,122.82643467187881L142.90520833333332,122.95792311429977L145.24791666666667,122.63456493616104L147.59062500000002,123.11214685440063L149.93333333333334,123.2100510597229L152.27604166666666,123.19077968597412L154.61875,122.83257126808167L156.96145833333333,122.812719643116L159.30416666666667,123.34688484668732L161.646875,123.35233569145203L163.98958333333334,123.20671021938324L166.33229166666666,123.22058349847794L168.67499999999998,123.30417484045029L171.01770833333333,123.28884214162827L173.36041666666668,123.23584586381912L175.703125,123.3343654870987L178.04583333333332,123.24119120836258L180.38854166666667,123.31796020269394L182.73125000000002,123.34259450435638L185.07395833333334,123.21314573287964L187.41666666666666,123.2293751835823L189.759375,123.30670684576035L192.10208333333333,123.1959667801857L194.44479166666667,123.01171064376831L196.7875,123.26874434947968L199.13020833333334,123.02512675523758L201.47291666666666,123.18124949932098L203.81562499999998,123.10156166553497L206.15833333333333,122.80109703540802L208.50104166666668,123.10790926218033L210.84375,122.73654848337173L213.18645833333332,123.06897968053818L215.52916666666667,122.9491314291954L217.87187500000002,122.71885961294174L220.21458333333334,122.55130767822266L222.55729166666666,122.75552093982697L224.9,122.27802693843842L227.24270833333333,122.52874821424484L229.58541666666667,122.69751340150833L231.928125,122.1623107790947L234.27083333333334,122.34273374080658L236.61354166666666,122.28365361690521L238.95624999999998,122.39319801330566L241.29895833333333,122.38634049892426L243.64166666666668,122.25006937980652L245.984375,122.26543724536896L248.32708333333332,122.08643853664398L250.66979166666667,122.01269388198853L253.01250000000002,122.15814352035522L255.35520833333334,121.94737166166306\" fill=\"none\" stroke=\"rgb(0, 119, 187)\" stroke-width=\"2px\" style=\"fill: none;\"/></g><g><path d=\"M28.1125,-1.905052661895752L30.455208333333335,27.632424533367157L32.797916666666666,46.419851183891296L35.140625,59.72940742969513L37.483333333333334,69.58423584699631L39.82604166666667,77.42726296186447L42.168749999999996,83.8555321097374L44.51145833333333,89.05145317316055L46.854166666666664,93.58692526817322L49.196875,97.3851090669632L51.53958333333333,100.89719384908676L53.88229166666667,103.86697232723236L56.225,106.48429214954376L58.567708333333336,108.94986748695374L60.91041666666667,111.17265164852142L63.253125000000004,113.19716572761536L65.59583333333333,115.18354147672653L67.93854166666667,116.75067692995071L70.28125,118.44165205955505L72.62395833333333,119.9330735206604L74.96666666666667,121.3135614991188L77.309375,122.60637879371643L79.65208333333334,123.97767066955566L81.99479166666667,125.08668899536133L84.33749999999999,126.23096197843552L86.68020833333334,127.18930840492249L89.02291666666666,128.16013902425766L91.36562500000001,129.10378575325012L93.70833333333333,129.95547145605087L96.05104166666666,130.87564438581467L98.39375,131.67635589838028L100.73645833333333,132.512708902359L103.07916666666667,133.19916367530823L105.421875,133.9141035079956L107.76458333333333,134.54091548919678L110.10729166666667,135.24477779865265L112.45,135.91243594884872L114.79270833333334,136.53147608041763L117.13541666666667,137.13221192359924L119.47812499999999,137.56240665912628L121.82083333333334,138.1182873249054L124.16354166666666,138.64441692829132L126.50625000000001,139.13761287927628L128.84895833333331,139.63870376348495L131.19166666666666,140.07992327213287L133.53437499999998,140.5843549966812L135.87708333333333,141.0750189423561L138.21979166666665,141.5375319123268L140.5625,141.81262373924255L142.90520833333332,142.27045953273773L145.24791666666667,142.7968528866768L147.59062500000002,142.97196567058563L149.93333333333334,143.33878993988037L152.27604166666666,143.85340243577957L154.61875,144.12916243076324L156.96145833333333,144.4348669052124L159.30416666666667,144.74797397851944L161.646875,145.08682310581207L163.98958333333334,145.40541619062424L166.33229166666666,145.65756171941757L168.67499999999998,145.9533315896988L171.01770833333333,146.25235438346863L173.36041666666668,146.5069791674614L175.703125,146.7914605140686L178.04583333333332,147.0831862092018L180.38854166666667,147.4273806810379L182.73125000000002,147.56762564182281L185.07395833333334,147.80368238687515L187.41666666666666,148.0701407790184L189.759375,148.26121926307678L192.10208333333333,148.54655340313911L194.44479166666667,148.7513381242752L196.7875,148.94834220409393L199.13020833333334,149.17062237858772L201.47291666666666,149.37681376934052L203.81562499999998,149.58204686641693L206.15833333333333,149.8495690524578L208.50104166666668,149.99429777264595L210.84375,150.19514381885529L213.18645833333332,150.37411615252495L215.52916666666667,150.55338740348816L217.87187500000002,150.75295865535736L220.21458333333334,150.97247824072838L222.55729166666666,151.0867877304554L224.9,151.2953968346119L227.24270833333333,151.36593252420425L229.58541666666667,151.58132001757622L231.928125,151.7923380434513L234.27083333333334,152.01574355363846L236.61354166666666,152.04243510961533L238.95624999999998,152.22210198640823L241.29895833333333,152.4011006951332L243.64166666666668,152.52877354621887L245.984375,152.6428984105587L248.32708333333332,152.82064869999886L250.66979166666667,152.9267379641533L253.01250000000002,153.13199743628502L255.35520833333334,153.18616300821304\" fill=\"none\" stroke=\"rgb(255, 112, 67)\" stroke-width=\"2px\" style=\"fill: none;\"/></g></g></g></g></g></g><g clip-path=\"url(#clip_1)\" transform=\"translate(48, 177)\"><clipPath id=\"clip_1\"><rect height=\"23\" width=\"281\"/></clipPath><g><g><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"0\" x2=\"0\" y1=\"0\" y2=\"5\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"23.427083333333332\" x2=\"23.427083333333332\" y1=\"0\" y2=\"5\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"46.854166666666664\" x2=\"46.854166666666664\" y1=\"0\" y2=\"5\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"70.28125\" x2=\"70.28125\" y1=\"0\" y2=\"5\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"93.70833333333333\" x2=\"93.70833333333333\" y1=\"0\" y2=\"5\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"117.13541666666667\" x2=\"117.13541666666667\" y1=\"0\" y2=\"5\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"140.5625\" x2=\"140.5625\" y1=\"0\" y2=\"5\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"163.98958333333334\" x2=\"163.98958333333334\" y1=\"0\" y2=\"5\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"187.41666666666666\" x2=\"187.41666666666666\" y1=\"0\" y2=\"5\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"210.84375\" x2=\"210.84375\" y1=\"0\" y2=\"5\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"234.27083333333334\" x2=\"234.27083333333334\" y1=\"0\" y2=\"5\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"257.69791666666663\" x2=\"257.69791666666663\" y1=\"0\" y2=\"5\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"281.125\" x2=\"281.125\" y1=\"0\" y2=\"5\"/></g><g transform=\"translate(0, 8)\"><text dx=\"0em\" dy=\"0.95em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: middle; visibility: hidden; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"0\" y=\"0\">-10</text><text dx=\"0em\" dy=\"0.95em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: middle; visibility: inherit; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"23.427083333333332\" y=\"0\">0</text><text dx=\"0em\" dy=\"0.95em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: middle; visibility: inherit; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"46.854166666666664\" y=\"0\">10</text><text dx=\"0em\" dy=\"0.95em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: middle; visibility: inherit; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"70.28125\" y=\"0\">20</text><text dx=\"0em\" dy=\"0.95em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: middle; visibility: inherit; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"93.70833333333333\" y=\"0\">30</text><text dx=\"0em\" dy=\"0.95em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: middle; visibility: inherit; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"117.13541666666667\" y=\"0\">40</text><text dx=\"0em\" dy=\"0.95em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: middle; visibility: inherit; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"140.5625\" y=\"0\">50</text><text dx=\"0em\" dy=\"0.95em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: middle; visibility: inherit; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"163.98958333333334\" y=\"0\">60</text><text dx=\"0em\" dy=\"0.95em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: middle; visibility: inherit; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"187.41666666666666\" y=\"0\">70</text><text dx=\"0em\" dy=\"0.95em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: middle; visibility: inherit; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"210.84375\" y=\"0\">80</text><text dx=\"0em\" dy=\"0.95em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: middle; visibility: inherit; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"234.27083333333334\" y=\"0\">90</text><text dx=\"0em\" dy=\"0.95em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: middle; visibility: inherit; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"257.69791666666663\" y=\"0\">100</text><text dx=\"0em\" dy=\"0.95em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: middle; visibility: hidden; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"281.125\" y=\"0\">110</text></g><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" x1=\"0\" x2=\"281.125\" y1=\"0\" y2=\"0\"/></g></g></g></g></svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(\"work/loss.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg viewBox=\"0 0 330 200\" xmlns=\"http://www.w3.org/2000/svg\"><g><g><g><g><g><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"48.875\" x2=\"43.875\" y1=\"177\" y2=\"177\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"48.875\" x2=\"43.875\" y1=\"160.90909090909088\" y2=\"160.90909090909088\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"48.875\" x2=\"43.875\" y1=\"144.81818181818178\" y2=\"144.81818181818178\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"48.875\" x2=\"43.875\" y1=\"128.7272727272727\" y2=\"128.7272727272727\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"48.875\" x2=\"43.875\" y1=\"112.63636363636357\" y2=\"112.63636363636357\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"48.875\" x2=\"43.875\" y1=\"96.54545454545446\" y2=\"96.54545454545446\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"48.875\" x2=\"43.875\" y1=\"80.45454545454537\" y2=\"80.45454545454537\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"48.875\" x2=\"43.875\" y1=\"64.36363636363625\" y2=\"64.36363636363625\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"48.875\" x2=\"43.875\" y1=\"48.27272727272714\" y2=\"48.27272727272714\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"48.875\" x2=\"43.875\" y1=\"32.181818181818045\" y2=\"32.181818181818045\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"48.875\" x2=\"43.875\" y1=\"16.090909090908923\" y2=\"16.090909090908923\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"48.875\" x2=\"43.875\" y1=\"0\" y2=\"0\"/></g><g transform=\"translate(38.875, 0)\"><text dx=\"0em\" dy=\"0.3em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: end; visibility: hidden; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"0\" y=\"177\">0.83</text><text dx=\"0em\" dy=\"0.3em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: end; visibility: inherit; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"0\" y=\"160.90909090909088\">0.84</text><text dx=\"0em\" dy=\"0.3em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: end; visibility: hidden; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"0\" y=\"144.81818181818178\">0.85</text><text dx=\"0em\" dy=\"0.3em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: end; visibility: inherit; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"0\" y=\"128.7272727272727\">0.86</text><text dx=\"0em\" dy=\"0.3em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: end; visibility: hidden; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"0\" y=\"112.63636363636357\">0.87</text><text dx=\"0em\" dy=\"0.3em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: end; visibility: inherit; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"0\" y=\"96.54545454545446\">0.88</text><text dx=\"0em\" dy=\"0.3em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: end; visibility: hidden; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"0\" y=\"80.45454545454537\">0.89</text><text dx=\"0em\" dy=\"0.3em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: end; visibility: inherit; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"0\" y=\"64.36363636363625\">0.9</text><text dx=\"0em\" dy=\"0.3em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: end; visibility: hidden; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"0\" y=\"48.27272727272714\">0.91</text><text dx=\"0em\" dy=\"0.3em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: end; visibility: inherit; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"0\" y=\"32.181818181818045\">0.92</text><text dx=\"0em\" dy=\"0.3em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: end; visibility: hidden; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"0\" y=\"16.090909090908923\">0.93</text><text dx=\"0em\" dy=\"0.3em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: end; visibility: hidden; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"0\" y=\"0\">0.94</text></g><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" x1=\"48.875\" x2=\"48.875\" y1=\"0\" y2=\"177\"/></g></g><g clip-path=\"url(#clip_0)\" transform=\"translate(48, 0)\"><clipPath id=\"clip_0\"><rect height=\"177\" width=\"281\"/></clipPath><g><g><g><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"0\" x2=\"0\" y1=\"0\" y2=\"177\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"23.427083333333332\" x2=\"23.427083333333332\" y1=\"0\" y2=\"177\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"46.854166666666664\" x2=\"46.854166666666664\" y1=\"0\" y2=\"177\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"70.28125\" x2=\"70.28125\" y1=\"0\" y2=\"177\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"93.70833333333333\" x2=\"93.70833333333333\" y1=\"0\" y2=\"177\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"117.13541666666667\" x2=\"117.13541666666667\" y1=\"0\" y2=\"177\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"140.5625\" x2=\"140.5625\" y1=\"0\" y2=\"177\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"163.98958333333334\" x2=\"163.98958333333334\" y1=\"0\" y2=\"177\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"187.41666666666666\" x2=\"187.41666666666666\" y1=\"0\" y2=\"177\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"210.84375\" x2=\"210.84375\" y1=\"0\" y2=\"177\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"234.27083333333334\" x2=\"234.27083333333334\" y1=\"0\" y2=\"177\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"257.69791666666663\" x2=\"257.69791666666663\" y1=\"0\" y2=\"177\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"281.125\" x2=\"281.125\" y1=\"0\" y2=\"177\"/></g><g><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"0\" x2=\"281.125\" y1=\"177\" y2=\"177\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"0\" x2=\"281.125\" y1=\"160.90909090909088\" y2=\"160.90909090909088\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"0\" x2=\"281.125\" y1=\"144.81818181818178\" y2=\"144.81818181818178\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"0\" x2=\"281.125\" y1=\"128.7272727272727\" y2=\"128.7272727272727\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"0\" x2=\"281.125\" y1=\"112.63636363636357\" y2=\"112.63636363636357\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"0\" x2=\"281.125\" y1=\"96.54545454545446\" y2=\"96.54545454545446\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"0\" x2=\"281.125\" y1=\"80.45454545454537\" y2=\"80.45454545454537\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"0\" x2=\"281.125\" y1=\"64.36363636363625\" y2=\"64.36363636363625\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"0\" x2=\"281.125\" y1=\"48.27272727272714\" y2=\"48.27272727272714\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"0\" x2=\"281.125\" y1=\"32.181818181818045\" y2=\"32.181818181818045\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"0\" x2=\"281.125\" y1=\"16.090909090908923\" y2=\"16.090909090908923\"/><line fill=\"rgb(0, 0, 0)\" opacity=\"0.25\" stroke=\"rgb(60, 60, 60)\" stroke-width=\"1px\" x1=\"0\" x2=\"281.125\" y1=\"0\" y2=\"0\"/></g></g></g><g><g><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(153, 153, 153)\" stroke-width=\"1.5px\" x1=\"0\" x2=\"281.125\" y1=\"1512.5454545454545\" y2=\"1512.5454545454545\"/></g></g><g><g><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(153, 153, 153)\" stroke-width=\"1.5px\" x1=\"23.427083333333332\" x2=\"23.427083333333332\" y1=\"0\" y2=\"177\"/></g></g><g><g><g><g><g><path d=\"M28.1125,183.0868141651153L30.455208333333335,163.80185326662925L32.797916666666666,136.07965603741727L35.140625,128.8478076891465L37.483333333333334,117.99998721209431L39.82604166666667,115.58940306576808L42.168749999999996,108.35755471749732L44.51145833333333,98.71502631360826L46.854166666666664,92.68847003850063L49.196875,89.07249790971922L51.53958333333333,85.45662169022987L53.88229166666667,83.04594163461158L56.225,79.43006541512221L58.567708333333336,78.22467743266705L60.91041666666667,78.22467743266705L63.253125000000004,75.81409328634082L65.59583333333333,73.40350914001456L67.93854166666667,73.40350914001456L70.28125,72.19812115755941L72.62395833333333,69.78753701123316L74.96666666666667,70.99282908439628L77.309375,66.17156488245176L79.65208333333334,69.78753701123316L81.99479166666667,70.99282908439628L84.33749999999999,66.17156488245176L86.68020833333334,69.78753701123316L89.02291666666666,68.58224493807005L91.36562500000001,67.37695286490693L93.70833333333333,66.17156488245176L96.05104166666666,66.17156488245176L98.39375,67.37695286490693L100.73645833333333,69.78753701123316L103.07916666666667,60.14500860734411L105.421875,68.58224493807005L107.76458333333333,63.76098073612552L110.10729166666667,66.17156488245176L112.45,64.96627280928864L114.79270833333334,62.555688662962396L117.13541666666667,62.555688662962396L119.47812499999999,63.76098073612552L121.82083333333334,64.96627280928864L124.16354166666666,62.555688662962396L126.50625000000001,61.35039658979929L128.84895833333331,63.76098073612552L131.19166666666666,64.96627280928864L133.53437499999998,62.555688662962396L135.87708333333333,64.96627280928864L138.21979166666665,64.96627280928864L140.5625,63.76098073612552L142.90520833333332,62.555688662962396L145.24791666666667,68.58224493807005L147.59062500000002,67.37695286490693L149.93333333333334,66.17156488245176L152.27604166666666,64.96627280928864L154.61875,66.17156488245176L156.96145833333333,63.76098073612552L159.30416666666667,64.96627280928864L161.646875,63.76098073612552L163.98958333333334,61.35039658979929L166.33229166666666,64.96627280928864L168.67499999999998,63.76098073612552L171.01770833333333,64.96627280928864L173.36041666666668,64.96627280928864L175.703125,64.96627280928864L178.04583333333332,61.35039658979929L180.38854166666667,64.96627280928864L182.73125000000002,63.76098073612552L185.07395833333334,67.37695286490693L187.41666666666666,67.37695286490693L189.759375,63.76098073612552L192.10208333333333,63.76098073612552L194.44479166666667,63.76098073612552L196.7875,66.17156488245176L199.13020833333334,64.96627280928864L201.47291666666666,64.96627280928864L203.81562499999998,67.37695286490693L206.15833333333333,63.76098073612552L208.50104166666668,63.76098073612552L210.84375,66.17156488245176L213.18645833333332,64.96627280928864L215.52916666666667,68.58224493807005L217.87187500000002,64.96627280928864L220.21458333333334,67.37695286490693L222.55729166666666,64.96627280928864L224.9,66.17156488245176L227.24270833333333,64.96627280928864L229.58541666666667,67.37695286490693L231.928125,62.555688662962396L234.27083333333334,69.78753701123316L236.61354166666666,68.58224493807005L238.95624999999998,66.17156488245176L241.29895833333333,66.17156488245176L243.64166666666668,67.37695286490693L245.984375,68.58224493807005L248.32708333333332,62.555688662962396L250.66979166666667,67.37695286490693L253.01250000000002,66.17156488245176L255.35520833333334,66.17156488245176\" fill=\"none\" stroke=\"rgb(0, 119, 187)\" stroke-width=\"2px\" style=\"fill: none;\"/></g><g><path d=\"M25.769791666666666,215.93152668259356L28.1125,176.45756389878005L30.455208333333335,152.6526857939633L32.797916666666666,136.68235002864483L35.140625,122.82125141403884L37.483333333333334,111.82275743917978L39.82604166666667,106.39889515529973L42.168749999999996,101.5776309533552L44.51145833333333,95.40040118044065L46.854166666666664,91.03115747191681L49.196875,88.017879334363L51.53958333333333,86.2098932699723L53.88229166666667,82.44334355267603L56.225,79.88198999925085L58.567708333333336,77.32073235511771L60.91041666666667,75.06082170659839L63.253125000000004,72.95148864659387L65.59583333333333,71.89687007123767L67.93854166666667,70.54090450026764L70.28125,68.28089794245626L72.62395833333333,65.56896680051621L74.96666666666667,63.91165423393241L77.309375,62.40501516515549L79.65208333333334,61.1997230919924L81.99479166666667,61.04904959418549L84.33749999999999,58.33711845224546L86.68020833333334,59.84375752102237L89.02291666666666,58.03577145663168L91.36562500000001,57.583750963210974L93.70833333333333,58.03577145663168L96.05104166666666,56.52913238785476L98.39375,54.87181982127096L100.73645833333333,54.721146323464055L103.07916666666667,53.666527748107825L105.421875,55.02249331907785L107.76458333333333,53.51585425030093L110.10729166666667,52.76248676126646L112.45,52.31056217713781L114.79270833333334,51.10517419468265L117.13541666666667,49.59853512590573L119.47812499999999,49.899882121519525L121.82083333333334,49.899882121519525L124.16354166666666,47.94122255932194L126.50625000000001,48.09189605712882L128.84895833333331,48.24256955493573L131.19166666666666,48.09189605712882L133.53437499999998,45.37996491518879L135.87708333333333,46.585256988351915L138.21979166666665,45.229291417381916L140.5625,44.77736683325327L142.90520833333332,45.68131191080258L145.24791666666667,44.023999344218794L147.59062500000002,44.62669333544636L149.93333333333334,44.17467284202567L152.27604166666666,44.023999344218794L154.61875,42.216013279828076L156.96145833333333,42.0653397820212L159.30416666666667,44.32534633983258L161.646875,43.571978850798075L163.98958333333334,42.818707271055644L166.33229166666666,42.0653397820212L168.67499999999998,42.0653397820212L171.01770833333333,42.96938076886255L173.36041666666668,42.668033773248766L175.703125,41.91466628421429L178.04583333333332,41.16139470447186L180.38854166666667,40.40802721543736L182.73125000000002,40.558700713244264L185.07395833333334,40.860047708858076L187.41666666666666,41.312068202278766L189.759375,40.40802721543736L192.10208333333333,40.106776129115644L194.44479166666667,39.654755635694926L196.7875,40.106776129115644L199.13020833333334,39.05206164446736L201.47291666666666,40.558700713244264L203.81562499999998,39.35340864008114L206.15833333333333,38.90138814666048L208.50104166666668,38.298790064724926L210.84375,37.24417148936871L213.18645833333332,39.35340864008114L215.52916666666667,36.94282449375493L217.87187500000002,37.54542257569045L220.21458333333334,36.34013050252733L222.55729166666666,38.14811656691805L224.9,37.394749077883546L227.24270833333333,37.54542257569045L229.58541666666667,36.34013050252733L231.928125,36.189457004720424L234.27083333333334,37.54542257569045L236.61354166666666,36.641477498141114L238.95624999999998,37.394749077883546L241.29895833333333,36.34013050252733L243.64166666666668,36.34013050252733L245.984375,35.13483842936421L248.32708333333332,36.03878350691352L250.66979166666667,34.2308933518149L253.01250000000002,35.285511927171086L255.35520833333334,35.43618542497799\" fill=\"none\" stroke=\"rgb(255, 112, 67)\" stroke-width=\"2px\" style=\"fill: none;\"/></g></g></g></g></g></g><g clip-path=\"url(#clip_1)\" transform=\"translate(48, 177)\"><clipPath id=\"clip_1\"><rect height=\"23\" width=\"281\"/></clipPath><g><g><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"0\" x2=\"0\" y1=\"0\" y2=\"5\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"23.427083333333332\" x2=\"23.427083333333332\" y1=\"0\" y2=\"5\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"46.854166666666664\" x2=\"46.854166666666664\" y1=\"0\" y2=\"5\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"70.28125\" x2=\"70.28125\" y1=\"0\" y2=\"5\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"93.70833333333333\" x2=\"93.70833333333333\" y1=\"0\" y2=\"5\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"117.13541666666667\" x2=\"117.13541666666667\" y1=\"0\" y2=\"5\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"140.5625\" x2=\"140.5625\" y1=\"0\" y2=\"5\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"163.98958333333334\" x2=\"163.98958333333334\" y1=\"0\" y2=\"5\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"187.41666666666666\" x2=\"187.41666666666666\" y1=\"0\" y2=\"5\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"210.84375\" x2=\"210.84375\" y1=\"0\" y2=\"5\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"234.27083333333334\" x2=\"234.27083333333334\" y1=\"0\" y2=\"5\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"257.69791666666663\" x2=\"257.69791666666663\" y1=\"0\" y2=\"5\"/><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" style=\"visibility: inherit;\" x1=\"281.125\" x2=\"281.125\" y1=\"0\" y2=\"5\"/></g><g transform=\"translate(0, 8)\"><text dx=\"0em\" dy=\"0.95em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: middle; visibility: hidden; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"0\" y=\"0\">-10</text><text dx=\"0em\" dy=\"0.95em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: middle; visibility: inherit; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"23.427083333333332\" y=\"0\">0</text><text dx=\"0em\" dy=\"0.95em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: middle; visibility: inherit; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"46.854166666666664\" y=\"0\">10</text><text dx=\"0em\" dy=\"0.95em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: middle; visibility: inherit; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"70.28125\" y=\"0\">20</text><text dx=\"0em\" dy=\"0.95em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: middle; visibility: inherit; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"93.70833333333333\" y=\"0\">30</text><text dx=\"0em\" dy=\"0.95em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: middle; visibility: inherit; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"117.13541666666667\" y=\"0\">40</text><text dx=\"0em\" dy=\"0.95em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: middle; visibility: inherit; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"140.5625\" y=\"0\">50</text><text dx=\"0em\" dy=\"0.95em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: middle; visibility: inherit; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"163.98958333333334\" y=\"0\">60</text><text dx=\"0em\" dy=\"0.95em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: middle; visibility: inherit; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"187.41666666666666\" y=\"0\">70</text><text dx=\"0em\" dy=\"0.95em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: middle; visibility: inherit; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"210.84375\" y=\"0\">80</text><text dx=\"0em\" dy=\"0.95em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: middle; visibility: inherit; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"234.27083333333334\" y=\"0\">90</text><text dx=\"0em\" dy=\"0.95em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: middle; visibility: inherit; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"257.69791666666663\" y=\"0\">100</text><text dx=\"0em\" dy=\"0.95em\" fill=\"rgb(50, 49, 63)\" stroke=\"none\" stroke-width=\"1px\" style=\"text-anchor: middle; visibility: hidden; font-family: &quot;Helvetica Neue&quot;, sans-serif; font-size: 12px; font-weight: 200;\" x=\"281.125\" y=\"0\">110</text></g><line fill=\"rgb(0, 0, 0)\" stroke=\"rgb(204, 204, 204)\" stroke-width=\"1px\" x1=\"0\" x2=\"281.125\" y1=\"0\" y2=\"0\"/></g></g></g></g></svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(\"work/accuracy.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 76. チェックポイント"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-1.1258, -1.1524, -0.2506, -0.4339],\n",
      "        [ 0.8487,  0.6920, -0.3160, -2.1152],\n",
      "        [ 0.3223, -1.2633,  0.3500,  0.3081],\n",
      "        ...,\n",
      "        [ 1.1469, -0.1733,  0.0637, -1.2699],\n",
      "        [-0.6212, -0.2381,  0.0892,  1.8008],\n",
      "        [-2.0627,  0.3222, -1.1390,  1.2418]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "W = nn.Parameter(torch.randn(300, 4), requires_grad=True)\n",
    "print(W)\n",
    "ntrain = len(train_x)\n",
    "nepoch = 10\n",
    "op = optim.SGD([W], lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a5d45e18f2f44358d335e0df76696c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm.notebook.tqdm(range(nepoch)):\n",
    "    train_loss = execution(train_x, train_y, op, criterion, W, batch_size=1)\n",
    "    valid_loss = execution(valid_x, valid_y, op, criterion, W, batch_size=1, is_train=False)\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'W': W,\n",
    "        'optimizer_state_dict': op.state_dict(),\n",
    "    }, f'./work/checkpoints/checkpoint_{epoch}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-1.8521, -0.5547,  0.3394, -0.8952],\n",
      "        [ 0.8031,  0.7012, -0.3991, -1.9957],\n",
      "        [ 0.0716, -0.3273, -0.9245,  0.8973],\n",
      "        ...,\n",
      "        [ 1.3952, -0.1296, -1.0046, -0.4936],\n",
      "        [-0.1049, -0.8423, -0.0874,  2.0654],\n",
      "        [-2.4062, -0.2060, -0.8290,  1.8035]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "W = nn.Parameter(torch.randn(300, 4), requires_grad=True)\n",
    "checkpoint = torch.load('./work/checkpoints/checkpoint_9.pt')\n",
    "op = optim.SGD([W], lr=0.01)\n",
    "W = checkpoint['W']\n",
    "op.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-1.8521, -0.5547,  0.3394, -0.8952],\n",
      "        [ 0.8031,  0.7012, -0.3991, -1.9957],\n",
      "        [ 0.0716, -0.3273, -0.9245,  0.8973],\n",
      "        ...,\n",
      "        [ 1.3952, -0.1296, -1.0046, -0.4936],\n",
      "        [-0.1049, -0.8423, -0.0874,  2.0654],\n",
      "        [-2.4062, -0.2060, -0.8290,  1.8035]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 77. ミニバッチ化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 78. GPU上での学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 79. 多層ニューラルネットワーク"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, input_size, num_hidden, hidden_dim, output_size, dropout):\n",
    "        super(MLP, self).__init__()\n",
    "        self.first_layer = nn.Linear(input_size, hidden_dim)\n",
    "        self.hidden_layers = nn.Sequential(OrderedDict([\n",
    "            (f'hidden_layer{i}', nn.Linear(hidden_dim, hidden_dim)) for i in range(num_hidden)\n",
    "        ]))\n",
    "        self.last_layer = nn.Linear(hidden_dim, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.first_layer(x))\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            x = self.dropout(self.relu(hidden_layer(x)))\n",
    "        x = self.last_layer(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (first_layer): Linear(in_features=300, out_features=300, bias=True)\n",
      "  (hidden_layers): Sequential(\n",
      "    (hidden_layer0): Linear(in_features=300, out_features=300, bias=True)\n",
      "    (hidden_layer1): Linear(in_features=300, out_features=300, bias=True)\n",
      "    (hidden_layer2): Linear(in_features=300, out_features=300, bias=True)\n",
      "  )\n",
      "  (last_layer): Linear(in_features=300, out_features=4, bias=True)\n",
      "  (softmax): LogSoftmax()\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(MLP(300, 3, 300, 4, 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataSets(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execution(data_x, data_y, op, criterion, model, batch_size=1, is_train=True, use_gpu=False):\n",
    "    if is_train: model.train()\n",
    "    else: model.eval()\n",
    "    ndata = len(data_x)\n",
    "    dataset = MyDataSets(data_x, data_y)\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    sum_loss, acc_score = 0, 0\n",
    "    for batch_x, batch_y in data_loader:\n",
    "        if use_gpu:\n",
    "            batch_x.cuda()\n",
    "            batch_y.cuda()\n",
    "        op.zero_grad()\n",
    "        out = model(batch_x)\n",
    "        loss = criterion(out, batch_y)\n",
    "        if is_train:\n",
    "            loss.backward()\n",
    "            op.step()\n",
    "        sum_loss += loss.data.item() * len(batch_x)\n",
    "        pred = torch.argmax(out, dim=1)\n",
    "        acc_score += np.sum((pred == batch_y).cpu().detach().numpy())\n",
    "    return sum_loss / ndata, acc_score / ndata * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45ceb25929d543a9a34743aedd2596b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 5, 'train_loss': 0.5253421511542931, 'train_acc': 79.05430711610487, 'valid_loss': 0.49559498837824617, 'valid_acc': 78.95131086142322}\n",
      "{'epoch': 10, 'train_loss': 0.4219149863675293, 'train_acc': 83.73595505617978, 'valid_loss': 0.4115068948670719, 'valid_acc': 83.37078651685394}\n",
      "{'epoch': 15, 'train_loss': 0.36295407133155994, 'train_acc': 86.23595505617978, 'valid_loss': 0.3737494556198406, 'valid_acc': 85.69288389513109}\n",
      "{'epoch': 20, 'train_loss': 0.3279724585652798, 'train_acc': 88.88576779026216, 'valid_loss': 0.35227308969819143, 'valid_acc': 88.23970037453184}\n",
      "{'epoch': 25, 'train_loss': 0.27843533531110387, 'train_acc': 90.83333333333333, 'valid_loss': 0.3318385514650452, 'valid_acc': 88.91385767790261}\n",
      "{'epoch': 30, 'train_loss': 0.23980837913041705, 'train_acc': 92.38764044943821, 'valid_loss': 0.31610511165209926, 'valid_acc': 89.66292134831461}\n",
      "{'epoch': 35, 'train_loss': 0.20354624445295513, 'train_acc': 93.78277153558052, 'valid_loss': 0.30821718475345367, 'valid_acc': 90.187265917603}\n",
      "{'epoch': 40, 'train_loss': 0.1724996701385198, 'train_acc': 94.57865168539325, 'valid_loss': 0.31778719541285366, 'valid_acc': 90.11235955056179}\n",
      "{'epoch': 45, 'train_loss': 0.14195168304086178, 'train_acc': 95.72097378277154, 'valid_loss': 0.3212107356567954, 'valid_acc': 91.08614232209737}\n",
      "{'epoch': 50, 'train_loss': 0.12049330926678153, 'train_acc': 96.54494382022472, 'valid_loss': 0.3342858394656735, 'valid_acc': 90.63670411985018}\n",
      "{'epoch': 55, 'train_loss': 0.09238248227464126, 'train_acc': 97.54681647940075, 'valid_loss': 0.35418945342888325, 'valid_acc': 91.08614232209737}\n",
      "{'epoch': 60, 'train_loss': 0.0710222901811314, 'train_acc': 98.25842696629213, 'valid_loss': 0.37423195169213114, 'valid_acc': 90.71161048689137}\n",
      "{'epoch': 65, 'train_loss': 0.05326716928334718, 'train_acc': 98.77340823970037, 'valid_loss': 0.40500236885824453, 'valid_acc': 91.08614232209737}\n",
      "{'epoch': 70, 'train_loss': 0.04009917727793647, 'train_acc': 99.09176029962546, 'valid_loss': 0.4430647137013268, 'valid_acc': 91.23595505617978}\n",
      "{'epoch': 75, 'train_loss': 0.02983996956870797, 'train_acc': 99.41011235955057, 'valid_loss': 0.46500585016686374, 'valid_acc': 90.71161048689137}\n",
      "{'epoch': 80, 'train_loss': 0.025576886180299945, 'train_acc': 99.48501872659176, 'valid_loss': 0.5014538564485557, 'valid_acc': 91.08614232209737}\n",
      "{'epoch': 85, 'train_loss': 0.020316455544631802, 'train_acc': 99.55992509363296, 'valid_loss': 0.5283007629132003, 'valid_acc': 90.93632958801498}\n",
      "{'epoch': 90, 'train_loss': 0.015016619153739362, 'train_acc': 99.65355805243445, 'valid_loss': 0.5543343848280246, 'valid_acc': 90.63670411985018}\n",
      "{'epoch': 95, 'train_loss': 0.012676849011122511, 'train_acc': 99.74719101123596, 'valid_loss': 0.5780189662948529, 'valid_acc': 90.86142322097378}\n",
      "{'epoch': 100, 'train_loss': 0.00832441792150171, 'train_acc': 99.812734082397, 'valid_loss': 0.6070958106258835, 'valid_acc': 90.93632958801498}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#torch.manual_seed(0)\n",
    "model = MLP(300, 3, 300, 4, 0.5)\n",
    "ntrain = len(train_x)\n",
    "nepoch = 100\n",
    "op = optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "    \n",
    "logger = list()\n",
    "for epoch in tqdm.notebook.tqdm(range(1, nepoch + 1)):\n",
    "    train_loss, train_acc = execution(train_x, train_y, op, criterion, model, batch_size=256)\n",
    "    with torch.no_grad():\n",
    "        valid_loss, valid_acc = execution(valid_x, valid_y, op, criterion, model, batch_size=256, is_train=False)\n",
    "    logger.append({'epoch':epoch, 'train_loss':train_loss, 'train_acc':train_acc, 'valid_loss':valid_loss, 'valid_acc':valid_acc})\n",
    "    if epoch % 5 == 0:\n",
    "        print({'epoch':epoch, 'train_loss':train_loss, 'train_acc':train_acc, 'valid_loss':valid_loss, 'valid_acc':valid_acc})\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer_state_dict': op.state_dict(),\n",
    "        }, f'./work/checkpoints/checkpoint_{epoch}.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.68539325842696\n"
     ]
    }
   ],
   "source": [
    "model_100 = MLP(300, 3, 300, 4, 0.5)\n",
    "checkpoint = torch.load('./work/checkpoints/checkpoint_100.pt')\n",
    "model_100.load_state_dict(checkpoint['model'])\n",
    "with torch.no_grad():\n",
    "    _, test_acc = execution(test_x, test_y, op, criterion, model_199, batch_size=256, is_train=False)\n",
    "    print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
